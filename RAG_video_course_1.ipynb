{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain langchain_community"
      ],
      "metadata": {
        "id": "Zjfq5XQOQ3kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRgG0YYIR10v",
        "outputId": "79b52380-3280-4150-aeba-f77c7b21b97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install faiss-cpu"
      ],
      "metadata": {
        "id": "-vFzd5GQWVEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import the necessary libraries"
      ],
      "metadata": {
        "id": "0WvDunXNXFwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "d3X-AEFVTf0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set the GOOGLE GEMINI api key\n",
        "[link to download api key](https://aistudio.google.com/app/apikey)"
      ],
      "metadata": {
        "id": "SDjSlHzvXLUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7LC0QNkSn4b",
        "outputId": "c7fd92b2-fbd2-4176-8c14-42ebb2b17bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set the LLM and embedding models"
      ],
      "metadata": {
        "id": "-UWaSGj1Xfap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")\n",
        "embeddings=GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
      ],
      "metadata": {
        "id": "IuYpnMGMSFBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load and Process Documents\n",
        "the document is about RAG"
      ],
      "metadata": {
        "id": "m1LYWYbkXkoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and Process Documents\n",
        "loader = TextLoader(\"/content/rag_report.txt\")  # Replace with your file path\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "DPhdcOg4T3a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict(documents[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXG0-EWeT-Tk",
        "outputId": "ede7917e-41a0-4eff-f189-94c26cb7dfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': None,\n",
              " 'metadata': {'source': '/content/rag_report.txt'},\n",
              " 'page_content': '# Report on Retrieval-Augmented Generation (RAG) and Its Use Cases\\n\\n## Introduction\\n\\nRetrieval-Augmented Generation (RAG) is a state-of-the-art approach that combines the strengths of information retrieval and generative modeling. RAG enables the generation of highly accurate, contextually relevant, and up-to-date content by integrating a retrieval mechanism with a generative language model. This technique has gained significant traction in various industries due to its ability to leverage external knowledge sources to augment generative tasks.\\n\\n---\\n\\n## What is RAG?\\n\\n### Definition\\n\\nRAG is a hybrid framework that uses a retriever to fetch relevant information from a knowledge base or external data source and then incorporates this retrieved information into the generation process of a language model.\\n\\n### Components of RAG\\n\\n1. **Retriever**: The retriever identifies relevant documents or passages from a knowledge base using techniques like vector similarity search.\\n\\n2. **Generator**: A large language model (e.g., GPT, LLaMA) generates responses by conditioning on the retrieved content.\\n\\n3. **Knowledge Base**: This can be a structured database, an unstructured document store, or a combination of both.\\n\\n---\\n\\n## Advantages of RAG\\n\\n- **Dynamic Knowledge Integration**: Updates responses dynamically using up-to-date external knowledge.\\n\\n- **Scalability**: Efficiently handles large-scale knowledge bases.\\n\\n- **Accuracy**: Reduces hallucinations by grounding the generated output in retrieved evidence.\\n\\n- **Flexibility**: Works with a variety of knowledge sources, including proprietary databases and open web data.\\n\\n---\\n\\n## Use Cases of RAG\\n\\n### 1. Customer Support\\n\\nRAG-powered chatbots and virtual assistants can provide accurate, context-sensitive responses to customer queries by retrieving relevant documents from FAQs, knowledge bases, and product manuals.\\n\\n- **Example**: A telecom company deploying a RAG-based assistant to resolve customer issues by retrieving troubleshooting guides.\\n\\n### 2. Legal Document Assistance\\n\\nLaw firms can use RAG to assist lawyers in retrieving case laws, statutes, and relevant precedents while drafting legal documents or preparing for cases.\\n\\n- **Example**: A legal assistant retrieving case summaries to aid in argument preparation.\\n\\n### 3. Scientific Research\\n\\nResearchers can utilize RAG to generate comprehensive literature reviews by retrieving and summarizing relevant academic papers.\\n\\n- **Example**: A medical researcher generating a report on the latest advancements in cancer immunotherapy.\\n\\n### 4. Education and Training\\n\\nRAG systems can create personalized learning experiences by retrieving course materials and providing context-specific explanations to students.\\n\\n- **Example**: An AI tutor offering detailed explanations from textbooks and online resources.\\n\\n### 5. E-Commerce\\n\\nIn e-commerce, RAG can improve product discovery and customer engagement by retrieving product specifications, reviews, and related items.\\n\\n- **Example**: A shopping assistant suggesting complementary products based on customer queries.\\n\\n### 6. Healthcare\\n\\nHealthcare applications of RAG include supporting medical professionals in diagnosing conditions by retrieving patient history and medical literature.\\n\\n- **Example**: An AI tool assisting doctors with differential diagnoses by referencing clinical guidelines.\\n\\n### 7. Business Intelligence\\n\\nOrganizations can use RAG to generate insights by retrieving and analyzing reports, market trends, and financial data.\\n\\n- **Example**: A business analyst using RAG to generate summaries of quarterly performance reports.\\n\\n### 8. Content Creation\\n\\nContent creators can benefit from RAG by using it to retrieve references and generate accurate, context-rich articles, blogs, and reports.\\n\\n- **Example**: A journalist generating a news article supported by retrieved data from credible sources.\\n\\n---\\n\\n## Technical Implementation\\n\\n### Step-by-Step Workflow\\n\\n1. **Data Preparation**:\\n\\n- Index the knowledge base using a vector database or search engine.\\n\\n- Ensure data is cleaned and semantically encoded.\\n\\n2. **Retriever Integration**:\\n\\n- Use retrievers like Dense Passage Retrieval (DPR) or BM25 for fetching relevant content.\\n\\n3. **Generator Integration**:\\n\\n- Incorporate the retrieved documents into the prompt of a generative model.\\n\\n4. **Fine-Tuning**:\\n\\n- Fine-tune the generative model to ensure better conditioning on retrieved information.\\n\\n5. **Feedback Loop**:\\n\\n- Implement a feedback mechanism to improve retrieval accuracy and relevance over time.\\n\\n### Tools and Frameworks\\n\\n- **OpenAI API**\\n\\n- **LangChain**\\n\\n- **Hugging Face Transformers**\\n\\n- **Pinecone, Weaviate, or FAISS** (for vector search)\\n\\n- **ElasticSearch or Vespa** (for traditional search)\\n\\n---\\n\\n## Challenges and Limitations\\n\\n### Challenges\\n\\n- **Latency**: Retrieving and generating responses in real-time can introduce delays.\\n\\n- **Data Quality**: Inaccurate or incomplete knowledge bases can affect output quality.\\n\\n- **Complexity**: Integrating retrieval and generation requires sophisticated pipelines.\\n\\n### Limitations\\n\\n- **Knowledge Boundaries**: RAG systems are only as good as their underlying knowledge base.\\n\\n- **Scalability Issues**: Managing large-scale databases can be resource-intensive.\\n\\n---\\n\\n## Future Directions\\n\\n- **Enhanced Retrieval Techniques**: Adoption of multimodal and adaptive retrieval methods.\\n\\n- **Integration with Knowledge Graphs**: Leveraging structured data for more precise retrieval.\\n\\n- **Real-Time Updates**: Dynamic incorporation of new information into the knowledge base.\\n\\n- **Explainability**: Providing users with transparent reasoning for generated outputs.\\n\\n---\\n\\n## Conclusion\\n\\nRetrieval-Augmented Generation represents a powerful paradigm for combining generative AI with information retrieval. By grounding responses in external knowledge, RAG addresses critical challenges in accuracy, relevance, and context-awareness. With its versatile applications across industries, RAG is poised to become a cornerstone of next-generation AI systems.\\n\\n',\n",
              " 'type': 'Document'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Step 2: Split Text into Manageable Chunks"
      ],
      "metadata": {
        "id": "pvOBYS_bXrX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: Split Text into Manageable Chunks\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "chunks = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "Tx1dE4ZlVCZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Create the vectorestore"
      ],
      "metadata": {
        "id": "ENKVKEABXuAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "  # Replace with your preferred embedding model\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "id": "_D6hNDVVVKbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Create a Retriever"
      ],
      "metadata": {
        "id": "14b3_ngYX9SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create a Retriever\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "KPohg3WyWc0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 5 Create the RAG Pipeline"
      ],
      "metadata": {
        "id": "EDTAXyRqX_tI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=\"Use the following context to answer the question.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        ")\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt_template}\n",
        ")"
      ],
      "metadata": {
        "id": "eM4ZlgA4Whsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Query the RAG System"
      ],
      "metadata": {
        "id": "vQBmiA9HYSrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Query the RAG System\n",
        "query = \"What is use case of RAG?\"  # Replace with your question\n",
        "result = qa_chain({\"query\": query})\n",
        "\n",
        "# Step 7: Display the Results\n",
        "print(\"Answer:\", result[\"result\"])\n",
        "print(\"\\nSource Documents:\")\n",
        "for doc in result[\"source_documents\"]:\n",
        "    print(f\"- {doc.page_content}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBiZwWC3WlEK",
        "outputId": "27edb924-acec-4950-8f06-f81ca1d184f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-0564493d8d77>:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain({\"query\": query})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Based on the provided context, here are some use cases of RAG (Retrieval-Augmented Generation):\n",
            "\n",
            "*   **Customer Support:** Providing accurate, context-sensitive responses to customer queries using FAQs, knowledge bases, and product manuals.\n",
            "*   **Legal Document Assistance:** Assisting lawyers by retrieving case laws, statutes, and precedents for drafting documents and preparing for cases.\n",
            "*   **Scientific Research:** (While not explicitly detailed, it's implied that RAG can be used in scientific research)\n",
            "*   **E-Commerce:** Improving product discovery and customer engagement by retrieving product specifications, reviews, and related items.\n",
            "*   **Healthcare:** Supporting medical professionals in diagnosing conditions by retrieving patient history and medical literature.\n",
            "*   **Business Intelligence:** Generating insights by retrieving and analyzing reports, market trends, and financial data.\n",
            "\n",
            "\n",
            "Source Documents:\n",
            "- ### 6. Healthcare\n",
            "Healthcare applications of RAG include supporting medical professionals in diagnosing conditions by retrieving patient history and medical literature.\n",
            "- **Example**: An AI tool assisting doctors with differential diagnoses by referencing clinical guidelines.\n",
            "### 7. Business Intelligence\n",
            "Organizations can use RAG to generate insights by retrieving and analyzing reports, market trends, and financial data.\n",
            "- - **Accuracy**: Reduces hallucinations by grounding the generated output in retrieved evidence.\n",
            "- **Flexibility**: Works with a variety of knowledge sources, including proprietary databases and open web data.\n",
            "---\n",
            "## Use Cases of RAG\n",
            "### 1. Customer Support\n",
            "RAG-powered chatbots and virtual assistants can provide accurate, context-sensitive responses to customer queries by retrieving relevant documents from FAQs, knowledge bases, and product manuals.\n",
            "- - **Example**: An AI tutor offering detailed explanations from textbooks and online resources.\n",
            "### 5. E-Commerce\n",
            "In e-commerce, RAG can improve product discovery and customer engagement by retrieving product specifications, reviews, and related items.\n",
            "- **Example**: A shopping assistant suggesting complementary products based on customer queries.\n",
            "### 6. Healthcare\n",
            "- - **Example**: A telecom company deploying a RAG-based assistant to resolve customer issues by retrieving troubleshooting guides.\n",
            "### 2. Legal Document Assistance\n",
            "Law firms can use RAG to assist lawyers in retrieving case laws, statutes, and relevant precedents while drafting legal documents or preparing for cases.\n",
            "- **Example**: A legal assistant retrieving case summaries to aid in argument preparation.\n",
            "### 3. Scientific Research\n"
          ]
        }
      ]
    }
  ]
}